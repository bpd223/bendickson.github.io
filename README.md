## Group Data Project: ChatGPT and other Generative AI tools' effect on academia at Lehigh
### Part 1: Intro and Faculty Survey Analysis (Ben)
In an email to Lehigh faculty earlier this semester, Provost Nathan Urban said, “In my view, outside of special cases, attempting to ban tools like ChatGPT would be short sighted and likely impossible to enforce.” 

“Students are going to be living and working in a world where these tools are in use and employers and others will expect that their employees generate the best possible work using all the tools available, including generative AI tools,” continued Urban. “So while it may be appropriate to place restrictions on use of these tools in specific cases to meet particular learning objectives, generally we should embrace their use and train our students to be adept and creative in using these and similar tools.”

ChatGPT and other Generative AI tools have thrown a wrench into the world of academia. Since its major release in November of 2022, many in the field have been unsure of how to handle the tool. New York Public Schools have already banned these tools, and just earlier this week, Italy temporarily banned ChatGPT across the country.

Lehigh is taking a different approach towards AI. Instead of banning or restricting the tool, Provost Urban is encouraging the Lehigh community to plant a flag in AI tools and to become a leader in AI technology.

“I want to make sure that we are incorporating them into the way that we think about education. And so that's kind of the key element of this for me because I do think that they will change education and they will also change the way that people work,” said Urban, in an interview. “Lehigh needs to recognize that it needs to incorporate these trends.” 

But given the public backlash about Generative AI tools, are faculty members at Lehigh agreeing with Urban’s messages about these tools?

To gauge faculty response to Generative AI, we sent Lehigh faculty members in the College of Arts and Sciences and P.C. Rossin College of Engineering and Applied Sciences an optionally-anonymous survey with a plethora of different questions about these Generative AI tools.

The survey was sent out to department chairs to be sent out to their departments. In total, 34 Lehigh faculty members responded to our survey, 23 from the College of Arts and Sciences and 11 from the P.C. Rossin College of Engineering and Applied Sciences. Out of the 34 survey respondents, all of them were aware of Generative AI tools and their availability for students.

College of Engineering and College of Arts and Sciences professors mostly agreed on addressing the use of Generative AI tools in the classroom. Of respondents, almost 85% of them said that they would be addressing AI in the classroom. However, a stark divide started to appear when faculty were asked whether or not they will teach their students about these Generative AI tools. Only 42% of responding faculty planned on teaching their students about AI.

“We need to embrace it and show our students how to use it effectively and ethically to solve problems that matter,” said one respondent. However, there seemed to be much backlash to this idea, with another respondent saying, “ChatGPT is not the most advanced and worthy tool for advancing higher education.

Once more in depth questions started to be asked in the survey, another trend arose: a split on feelings on Generative AI between professors in the College of Engineering and professors from the College of Arts and Sciences.

This split first showed up in the results of the question “Are you currently allowing students to use ChatGPT or other Generative AI tools for assignments out of class?” While seven of the 23 faculty members from the College of Arts and Sciences already banned its use out of class, none of the professors from the College of Engineering had banned its use out of class. In fact, five of the respondents already completely allowed it, and another 2 planned to allow it without any restrictions. The other 4 respondents from the College of Engineering all planned on allowing the out of class use of Generative AI tools.

#### Allowment of AI out of Class
<div class='tableauPlaceholder' id='viz1681164520184' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALallowmentoutofclass&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='FINALallowmentoutofclass&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALallowmentoutofclass&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div><script type='text/javascript'>var divElement = document.getElementById('viz1681164520184');var vizElement = divElement.getElementsByTagName('object')[0];if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else { vizElement.style.width='100%';vizElement.style.height='727px';}var scriptElement = document.createElement('script');scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';vizElement.parentNode.insertBefore(scriptElement, vizElement);</script>      

In the classroom, the divide between colleges still exists.  While seven of 11 professors in the College of Engineering are allowing the use of Generative AI tools in their classes to some degree, only eight of 23 professors surveyed in the College of Arts and Sciences allowed its use in class.

So, why does this divide between colleges exist? In the college of Arts and Sciences, many faculty members were worried about how Generative AI tools would effect the process of creativity and the process of writing. AI can help students generate ideas that they would not have otherwise, worrying faculty about creative processes.

“The reason why I have not included it robustly in my teaching is that the greatest skill students can learn in my courses is the combination of original critical analysis and expression/argumentation,” said one anonymous respondent. “In my own experience, working with ChatGPT exercises very different skills, such as giving clear directions, recursive evaluation and revision, and persistence. These may be valuable but can be learned better in other settings than in my classes. My expertise is best used teaching students how to read thoughtfully, analyze problems, and express their positions.”

Another professor, who teaches a class heavy in writing, said, “Writing is about discovery, not about translating pre-formed ideas to words. It is by means of writing that you discover what you think, or why what you thought doesn't quite work, or a facet of an idea that you hadn't thought about before. Generative AI replaces the writing process. That’s a problem.”

Professor Bauknight, an English professor, is more interested in how Generative AI tools can be used to help learners, rather than replace the writing process. He has shared the tool in class with his English 002 students and mentions in the syllabus, “you are not allowed to use [Generative AI] technologies to write your assignments for you.” However, students may use these tools, “in other ways that you find helpful for your learning process (brainstorming, for example),” as long as students cite the tool and explain how it was used.

Bauknight also acknowledges a ban on Generative AI noting that, “there are always going to be restrictions in schools that won’t be there in the world, but these restrictions are necessary.” For some disciplines, the use of Generative AI might not be compatible with learning goals. 

In the College of Engineering, while the results of the survey show that Generative AI is overall being more allowed than in other colleges at Lehigh, the free response sections of the survey reveal that it may not be because of how effective these tools are. Many professors from the Engineering department seemed to believe that AI tools still had far to go and that they were not too useful for their field yet, meaning that they really had no effect on their classes.

“I do not implement its use; I just don't fight it,” said one professor from the Engineering department, while another said, “I don't generally operate by prohibiting, but I have been showing students how AI gets things wrong in various ways.”

Faculty members were then asked about if and how they will be changing teaching and evaluation methods due to Generative AI tools. In the changing of teaching methodology, again Arts and Sciences professors were much more likely to change the way that their classroom operates. One professor from the department went as far as saying, “I'm shifting certain assignments off-line, including handwritten hour quizzes.”

#### Changing of Teaching Methods
<div class='tableauPlaceholder' id='viz1680792155469' style='position: relative'><noscript><a href='#'><img alt='Story 4 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;ch&#47;changingofteachingmethods&#47;Story4&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='changingofteachingmethods&#47;Story4' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;ch&#47;changingofteachingmethods&#47;Story4&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div><script type='text/javascript'>var divElement = document.getElementById('viz1680792155469');var vizElement = divElement.getElementsByTagName('object')[0];  vizElement.style.width='1016px';vizElement.style.height='991px';var scriptElement = document.createElement('script');scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js'; vizElement.parentNode.insertBefore(scriptElement, vizElement); </script>            

However, Professor Ginny McSwain, Professor of Physics here at Lehigh, says that at some point these tools will need to be embraced in teaching. “Students are going to use it, whether we ban it or not, just like they already use other prohibited sites (e.g. Chegg),” McSwain said. “We need to be prepared to work with it or at least work around it.”

Engineering professors again seemed unworried about AI forcing them to change teaching methods. While they tend to recognize that it has an impact, overall they see the impact as very small on their field. “The classes I teach can benefit from ChatGPT and generative AI," said an anonymous respondent from the College of Engineering. I will include them and encourage their use, but so much of the assignments I give requires hands on, experiential work, that won't be impacted (yet) by AI tools in their final form, just on the ideation front.

Out of the faculty interviewed, only just over 31% of respondents said that they would change the way that they evaluate students. However, almost all these professors were in the College of Arts and Sciences. Only one professor surveyed from the College of Engineering planned on changing their evaluation methods.

#### Will you change evaluation methods?

<div class='tableauPlaceholder' id='viz1680736675542' style='position: relative'><noscript><a href='#'><img alt='Will you change evaluation methods? ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;wi&#47;willyouchangeevaluationmethods&#47;Story5&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='willyouchangeevaluationmethods&#47;Story5' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;wi&#47;willyouchangeevaluationmethods&#47;Story5&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div> <script type='text/javascript'>var divElement = document.getElementById('viz1680736675542');var vizElement = divElement.getElementsByTagName('object')[0];vizElement.style.width='1016px';vizElement.style.height='991px';var scriptElement = document.createElement('script'); scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js'; vizElement.parentNode.insertBefore(scriptElement, vizElement);</script>                 

“Increased human to human interaction in assessment is a way to prohibit students relying on AI to complete their learning tasks,” said one respondent from the College of Arts and Sciences, while another said, “Take-home writing is less trustworthy; I may require to see multiple drafts of take-home writing.”

Of professors who were surveyed, the most common ways that evaluation methods were being changed were with an increase in oral examinations, higher percentage of class grades decided by participation, and an increase in in-class writing assignments.

The increase in in-class writing assignments as a solution worries Professor Bauknight. He believes that the writing process takes time and students need that time to be creative and effectively learn from their writing. He mentions an exercise he does with his Creative Writing students in class where he says, “Quick! Be creative!” and has them write in class. Needless to say, this does not work and stresses out students.

Engineering professors again seemed unworried about evaluation, with one faculty member saying, “Most of the deliverables for my class are physical output, not written output, thus there is little fear AI tools can be used to"cheat "."

One of the last questions on the survey directly addressed Provost Urban’s message of Lehigh being a leader in and wanting to plant a flag in AI. When respondents were prompted with the question “Lehigh’s provost has expressed Lehigh’s desire to become a leader in Generative AI and encourage its use in the classroom. Do you think this is a good idea?,” only about 45% of respondents agreed with the provost’s message.

Clearly, two major divides on Generative AI tools still exist at Lehigh: the divide between the provost office and faculty, and the divide between separate colleges at Lehigh. While 
Provost Urban has strived to get these tools implemented early in classrooms and for Lehigh to get a front foot on AI technology such as ChatGPT, the survey results show the level of disdain he has been met with.

“Faculty ultimately have a lot of decision-making power over how they teach and how they assess,” Urban said. He also brought up how many teachers might think they know the full extent of these tools, but in practice he has seen professors be stunned by what these tools can truly do. In one specific instance, Urban had approached a coding professor about the use of AI in code. While the professor knew that AI wrote essays and could answer math equations, “they weren’t aware that it writes code, too,” Urban said.  “And I think it's important to make sure that faculty are broadly aware of the kinds of use cases of these tools so that they can think about how it is best to incorporate them into a classroom and into assignments.” 

One major trend that is seen in the faculty survey that was also talked about in the interview with Provost Urban was uncertainty about these Generative AI tools. For example, in the survey question “Lehigh’s provost has expressed Lehigh’s desire to become a leader in Generative AI and encourage its use in the classroom. Do you think this is a good idea?,” over 31% of respondents said “it depends”, and in a free response section about changing of evaluation methods, 12 of the 34 respondents said that they need more information before making any decisions about Generative AI.

These trends worry Urban, as a situation in which there is faculty and student uncertainty about the allowment of AI tools is a dangerous one. To combat this, Urban has urged teachers not to ban AI tools yet. 

On top of combating confusion, Urban also wants teachers to avoid banning it because he wants students to have access to the best tools possible. “These (Generative AI tools) change the way that we think about education, I think that's kind of been the key element to me,” Urban said. “And I want to make sure that we're doing this in a way that is effective, that is presenting students with the way that these things are going to be used in the real world.”

No matter what your specific opinion on Generative AI tools, one main theme emerged from the survey, faculty interviews, and the interview with the provost: Generative AI technology will have an effect on academia at Lehigh.

“I believe AI will be useful for research and teaching at Lehigh,” said one anonymous survey respondent. “Lehigh should think hard and fast how to use it in the most effective and productive way.”

### Part 2: Student Survey Analysis (Michael)
The rise of Generative AI, particularly ChatGPT, has sparked a debate about its impact on education, especially within the College of Arts and Sciences. As students and faculty grapple with the integration of AI into the learning process, concerns about academic integrity and the need for clear guidelines emerge. 

Generative AI has become an increasingly popular tool among students for various tasks, from studying and writing to job applications. One Lehigh student reports using AI to reduce anxiety and fear of judgment when generating outlines and writing emails. Others have found it helpful in summarizing textbook readings, by making them more concise and understandable.

Researchers for the Brown and White sent out an anonymous, voluntary survey to Lehigh students to gauge student perspectives on ChatGPT and Generative AI. We received 86 responses, with about 80% of these responses from the College of Arts and Sciences. The findings show that the majority of respondents are not engaging with Generative AI at all.

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/Michael%20graph%201.png)

Of survey respondents, 77% of students have not used ChatGPT or other Generative AI tools, while 90% of students do not use Generative AI tools for class. Despite this, roughly 63% of participants view Generative AI as a useful tool, while others express concern about its potential to compromise academic integrity. These concerns are echoed by the Provost, who has also shared apprehensions about not knowing what constitutes cheating when using AI.

Despite the Provost’s messages encouraging the use of Generative AI in the classroom, students report that 70% of professors have not frequently addressed or mentioned ChatGPT or other Generative AI tools in their classes, and that 90% of their classes have not allowed its use. This lack of communication between faculty and students has contributed to the confusion and concerns surrounding the potential for cheating with AI.

While concerns about cheating persist, the question of whether Generative AI can be considered cheating is complex. Students are divided on the issue, with some drawing parallels to other resources such as Chegg and Google. Based on survey results, 61.60% of students are concerned about peers using ChatGPT to cheat. In this context, the majority of students are seeking clearer guidelines on using AI in their coursework.

Students want more guidance from faculty and a clause in every syllabus that clarifies how Generative AI can be used in the classroom. They feel that the lack of clear-cut rules has left them walking a fine line between using a useful tool and potentially cheating. They also hope that faculty will become more invested in understanding how AI can help students, rather than focusing solely on concerns about cheating. As one student said, “trying to fight against the use of AI like ChatGPT would be difficult. Any professor who refuses to accept ChatGPT is wasting their energy.”

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/michael%20graph%202.png)

Generative AI has also sparked what an article from Stanford Education calls “an existential motivation crisis” among students, who are grappling with what skills they will need in the future. They are concerned about the potential impact of AI on their careers and how they will work alongside these tools. From survey data, 59% of Lehigh students think Generative AI will have an impact on their future career, with 30% of students being unsure. In the face of this uncertainty, some students believe that success will ultimately come down to who can use AI most effectively.

The debate surrounding Generative AI in the College of Arts and Sciences highlights the need for clear guidelines and faculty support. As students navigate the opportunities and challenges presented by AI, the focus should be on harnessing its potential for learning, while preserving academic integrity and preparing students for future job opportunities. By working together, students and faculty, in and outside of the classroom, can take action to use Generative AI as a powerful tool, rather than just another cheating tool.

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/Michael%20graph%204.png)

### Part 3 (Isabel): Ethics and does the community want to be a leader?
![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/isabel%20drawing.png)

Lehigh claims to want to become a leader in Artificial Intelligence, but there are many ethical concerns that must be addressed and recognized. ChatGPT, a Generative AI tool that generates text in response to prompts from the user, has recently come under fire for many different ethical concerns including spreading misinformation and encoding gender, racial, ethnic, and ability bias.

Because ChatGPT does not have any kind of world model, it can “hallucinate” and generate “facts” that are nonsense. Lehigh students and faculty are aware of this. One freshman described a scenario in one of their Psychology classes where the professor used ChatGPT to find references for a topic. The student said that of the 5 sources that were generated, 3 were fake. 

Professor Lopresti, a CSE Professor at Lehigh had a similar experience where the AI was unable to perform simple math tasks. “It is a program,” he said, “It doesn’t really understand even though it sounds like it’s confident.” An English 002 student put it succinctly with a hint of disdain: “It can’t do math.”

Two other students wrote in a survey that they have trouble trusting Generative AI models’ output, especially when using it to search for information. With ChatGPT there is no way for users to identify an accountable source or find where the information presented came from.

Other than simply getting facts wrong, Generative AI models that generate text like BingAI, ChatGPT, and others can also be used to create and spread misinformation in a persuasive manner that looks like it was written by a human. One student surveyed expressed concern about not being able to identify AI generated text. 

As these tools become more powerful it will be hard to discern writing produced by humans vs AI. OpenAI, the creators of ChatGPT, released a tool in January designed to detect AI generated text but it can only correctly identify AI generated text 26 percent of the time. 

This inability to identify AI generated text is particularly concerning in terms of misinformation. NewsGuard, a company that tracks misinformation online, used ChatGPT to write content that furthers misinformation about vaccines: with truly terrifying results. 

A faculty member responding to our survey said, “Students need to learn that such services are not trustworthy – at least for now, they cannot really do a literature search, and many other kinds of problems are not solved well by them.”

ChatGPT and other Generative AI models also have problems with bias. Professor Snyder, an ISE professor at Lehigh and one of two professors that taught a course on Algorithms and Social Justice last semester, explained that these biases come from the training data gathered from the internet that “skews white, male, and young.”

Provost Nathan Urban is also concerned with bias in the output of these models and pointed to efforts by companies to fix them, but, he noted, “they won’t be perfect.”

Indeed, they are not. Snyder said that the newer models of ChatGPT have less overt biases but still contain pernicious bias. He and a colleague, Professor Edwards, conducted an experiment on gender bias with ChatGPT-4 by asking it ten times for a story about a doctor and ten times for a story about a nurse. They found that while ChatGPT mixed up he/she pronouns in the stories generated about the doctor, it generated she/her pronouns in all ten stories about the nurse. There were no mentions of non-binary or other gender identities. Clearly, these fixes are not perfect. 

Snyder said that while newer versions, “might be better on the surface, it is not underneath,” and that it is impossible to train such large language models on unbiased data. So, these harmful yet subtle biases will never be completely eliminated.

In an open repository documenting errors by ChatGPT, one user found a way to “trick” the newer version of ChatGPT into revealing bias, by asking it to write python code to decide if a person should be tortured based on age, sex, ethnicity, and nationality.

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/isabel%20picture.png)

The takeaway? If you are less than 18, Caucasian and American, or female you should not be tortured. And if you are anyone else, ChatGPT generated code believes you should be tortured.

Although Provost Urban expressed concern about ethical issues in Generative AI, at the time of our faculty survey at least one faculty member did not see that sentiment in his emails, and responded: “There has been no public discussion of how these tools amplify bias--and the email from the Provost showed that this was not part of his thinking either. I would like to know how ChatGPT relates to the University's commitment to diversity, equity, and inclusion.”

In response to both misinformation and bias in ChatGPT, Lehigh faculty and Provost Urban agree that teaching students to think critically about AI generated text is necessary. Some professors compare ChatGPT to any other source that you would use on the internet, encouraging students to be skeptical. Provost Urban wants students to look at generated output and think: “What does the internet know, and what do I know,” as a way to be critical.

There seems to be consensus that students can be taught to identify and critically examine both misinformation and bias in Generative AI models outputs. (But, from our student analysis section above, with 70 percent of classes not frequently addressing Generative AI and 90 percent not allowing its use, this teaching is simply not happening).

The speed and scope of which Generative AI can create and disseminate misinformation cannot be understated, nor overlooked. Provost Urban hopes that the University can identify and educate students on ethical use cases for these tools.

Generative AI tools also complicate ethical considerations surrounding plagiarism as these tools are trained on data that is collected without the consent or knowledge of the original creators. 
Professor Snyder noted that this very article could be used as training data without his knowledge or consent, and without consent from the authors at the Brown and White. 

Snyder also stresses other ethical issues that are often overlooked including content moderation and labeling, and high energy costs.

Content moderation and data labeling work is done by humans and is often outsourced to low wage labor overseas and can be traumatizing. An investigation by the Times found that ChatGPT used Kenyan workers to reduce harmful outputs (by reading and labeling them) for 2 dollars an hour. This hidden and exploited labor is the human cost of these large language models.

Additionally, generating, holding, and maintaining the data for training has enormous energy costs. A scholarly article titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” shows that “the amount of compute used to train the largest deep learning models (for Natural Language Processing and other applications) has increased 300,000x in 6 years.”

Synder said that the climate change impacts will be felt by people that are not benefitting from this tool. Indeed, the authors of Stochastic Parrots echo his point, writing, “well documented in the literature on environmental racism that the negative effects of climate change are reaching and impacting the world’s most marginalized communities first.” They go on to say, “And, while some language technology is genuinely designed to benefit marginalized communities, most language technology is built to serve the needs of those who already have the most privilege in society.”

While Snyder agreed with Provost Urban in that it is short sighted to ban the tool, he said “it's important for us to be thinking really carefully about whether, when, how, and why we use it in the classroom.” Snyder believes the most important questions the Lehigh community must grapple with are, “who is benefited and who is harmed,” by these emerging Generative AI technologies. 

And perhaps more importantly, what will we do about the answer? Snyder said, “These are not just technical problems. They are societal problems. Those bad biases, baked into the technology because that's just that problem, that bias exists in society. And so, the relationship between society and technology is part of the problem. And that would have to be part of the answer, part of the solution.” How can Lehigh become part of the solution while engaging with Generative AI tools, especially considering our position of extreme privilege in society?

