## Group Data Project: ChatGPT and other Generative AI tools' effect on academia at Lehigh
### Part 1: Intro and Faculty Survey Analysis (Ben)
In an email to Lehigh faculty earlier this semester, Provost Nathan Urban said, “In my view, outside of special cases, attempting to ban tools like ChatGPT would be short sighted and likely impossible to enforce.” 

“Students are going to be living and working in a world where these tools are in use and employers and others will expect that their employees generate the best possible work using all the tools available, including generative AI tools,” continued Urban. “So while it may be appropriate to place restrictions on use of these tools in specific cases to meet particular learning objectives, generally we should embrace their use and train our students to be adept and creative in using these and similar tools.”

ChatGPT and other Generative AI tools have thrown a wrench into the world of academia. Since its major release in November of 2022, many in the field have been unsure of how to handle the tool. New York Public Schools have already banned these tools, and just earlier this week, Italy temporarily banned ChatGPT across the country.

Lehigh is taking a different approach towards AI. Instead of banning or restricting the tool, Provost Urban is encouraging the Lehigh community to plant a flag in AI tools and to become a leader in AI technology.

“I want to make sure that we are incorporating them into the way that we think about education. And so that's kind of the key element of this for me because I do think that they will change education and they will also change the way that people work,” said Urban, in an interview. “Lehigh needs to recognize that it needs to incorporate these trends.” 

But given the public backlash about Generative AI tools, are faculty members at Lehigh agreeing with Urban’s messages about these tools?

To gauge faculty response to Generative AI, we sent Lehigh faculty members in the College of Arts and Sciences and P.C. Rossin College of Engineering and Applied Sciences an optionally-anonymous survey with a plethora of different questions about these Generative AI tools.

The survey was sent out to department chairs to be sent out to their departments. In total, 34 Lehigh faculty members responded to our survey, 23 from the College of Arts and Sciences and 11 from the P.C. Rossin College of Engineering and Applied Sciences. Out of the 34 survey respondents, all of them were aware of Generative AI tools and their availability for students.

College of Engineering and College of Arts and Sciences professors mostly agreed on addressing the use of Generative AI tools in the classroom. Of respondents, almost 85% of them said that they would be addressing AI in the classroom. However, a stark divide started to appear when faculty were asked whether or not they will teach their students about these Generative AI tools. Only 42% of responding faculty planned on teaching their students about AI.

“We need to embrace it and show our students how to use it effectively and ethically to solve problems that matter,” said one respondent. However, there seemed to be much backlash to this idea, with another respondent saying, “ChatGPT is not the most advanced and worthy tool for advancing higher education.

Once more in depth questions started to be asked in the survey, another trend arose: a split on feelings on Generative AI between professors in the College of Engineering and professors from the College of Arts and Sciences.

This split first showed up in the results of the question “Are you currently allowing students to use ChatGPT or other Generative AI tools for assignments out of class?” While seven of the 23 faculty members from the College of Arts and Sciences already banned its use out of class, none of the professors from the College of Engineering had banned its use out of class. In fact, five of the respondents already completely allowed it, and another 2 planned to allow it without any restrictions. The other 4 respondents from the College of Engineering all planned on allowing the out of class use of Generative AI tools.

#### Allowment of AI out of Class
<div class='tableauPlaceholder' id='viz1681165047802' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALallowmentoutofclass&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='FINALallowmentoutofclass&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALallowmentoutofclass&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div><script type='text/javascript'>var divElement = document.getElementById('viz1681165047802');var vizElement = divElement.getElementsByTagName('object')[0];if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else { vizElement.style.width='100%';vizElement.style.height='727px';}var scriptElement = document.createElement('script');scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';vizElement.parentNode.insertBefore(scriptElement, vizElement);</script>   

In the classroom, the divide between colleges still exists.  While seven of 11 professors in the College of Engineering are allowing the use of Generative AI tools in their classes to some degree, only eight of 23 professors surveyed in the College of Arts and Sciences allowed its use in class.

So, why does this divide between colleges exist? In the college of Arts and Sciences, many faculty members were worried about how Generative AI tools would effect the process of creativity and the process of writing. AI can help students generate ideas that they would not have otherwise, worrying faculty about creative processes.

“The reason why I have not included it robustly in my teaching is that the greatest skill students can learn in my courses is the combination of original critical analysis and expression/argumentation,” said one anonymous respondent. “In my own experience, working with ChatGPT exercises very different skills, such as giving clear directions, recursive evaluation and revision, and persistence. These may be valuable but can be learned better in other settings than in my classes. My expertise is best used teaching students how to read thoughtfully, analyze problems, and express their positions.”

Another professor, who teaches a class heavy in writing, said, “Writing is about discovery, not about translating pre-formed ideas to words. It is by means of writing that you discover what you think, or why what you thought doesn't quite work, or a facet of an idea that you hadn't thought about before. Generative AI replaces the writing process. That’s a problem.”

Professor Bauknight, an English professor, is more interested in how Generative AI tools can be used to help learners, rather than replace the writing process. He has shared the tool in class with his English 002 students and mentions in the syllabus, “you are not allowed to use [Generative AI] technologies to write your assignments for you.” However, students may use these tools, “in other ways that you find helpful for your learning process (brainstorming, for example),” as long as students cite the tool and explain how it was used.

Bauknight also acknowledges a ban on Generative AI noting that, “there are always going to be restrictions in schools that won’t be there in the world, but these restrictions are necessary.” For some disciplines, the use of Generative AI might not be compatible with learning goals. 

In the College of Engineering, while the results of the survey show that Generative AI is overall being more allowed than in other colleges at Lehigh, the free response sections of the survey reveal that it may not be because of how effective these tools are. Many professors from the Engineering department seemed to believe that AI tools still had far to go and that they were not too useful for their field yet, meaning that they really had no effect on their classes.

“I do not implement its use; I just don't fight it,” said one professor from the Engineering department, while another said, “I don't generally operate by prohibiting, but I have been showing students how AI gets things wrong in various ways.”

Faculty members were then asked about if and how they will be changing teaching and evaluation methods due to Generative AI tools. In the changing of teaching methodology, again Arts and Sciences professors were much more likely to change the way that their classroom operates. One professor from the department went as far as saying, “I'm shifting certain assignments off-line, including handwritten hour quizzes.”

#### Changing of Teaching Methods
<div class='tableauPlaceholder' id='viz1681165790295' style='position: relative'><noscript><a href='#'><img alt='Dashboard 3 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALchangeofteachingmethod&#47;Dashboard3&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='FINALchangeofteachingmethod&#47;Dashboard3' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALchangeofteachingmethod&#47;Dashboard3&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div><script type='text/javascript'>var divElement = document.getElementById('viz1681165790295');var vizElement = divElement.getElementsByTagName('object')[0];if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else { vizElement.style.width='100%';vizElement.style.height='727px';}var scriptElement = document.createElement('script');scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js'; vizElement.parentNode.insertBefore(scriptElement, vizElement);</script>          

However, Professor Ginny McSwain, Professor of Physics here at Lehigh, says that at some point these tools will need to be embraced in teaching. “Students are going to use it, whether we ban it or not, just like they already use other prohibited sites (e.g. Chegg),” McSwain said. “We need to be prepared to work with it or at least work around it.”

Engineering professors again seemed unworried about AI forcing them to change teaching methods. While they tend to recognize that it has an impact, overall they see the impact as very small on their field. “The classes I teach can benefit from ChatGPT and generative AI," said an anonymous respondent from the College of Engineering. I will include them and encourage their use, but so much of the assignments I give requires hands on, experiential work, that won't be impacted (yet) by AI tools in their final form, just on the ideation front.

Out of the faculty interviewed, only just over 31% of respondents said that they would change the way that they evaluate students. However, almost all these professors were in the College of Arts and Sciences. Only one professor surveyed from the College of Engineering planned on changing their evaluation methods.

#### Will you change evaluation methods?

<div class='tableauPlaceholder' id='viz1681165392476' style='position: relative'><noscript><a href='#'><img alt='Dashboard 2 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALchangeofevaluationmethod&#47;Dashboard2&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='FINALchangeofevaluationmethod&#47;Dashboard2' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;FI&#47;FINALchangeofevaluationmethod&#47;Dashboard2&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /><param name='filter' value='publish=yes' /></object></div><script type='text/javascript'>var divElement = document.getElementById('viz1681165392476');var vizElement = divElement.getElementsByTagName('object')[0];if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1000px';vizElement.style.height='827px';} else { vizElement.style.width='100%';vizElement.style.height='727px';}var scriptElement = document.createElement('script');scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js'; vizElement.parentNode.insertBefore(scriptElement, vizElement);</script>                

“Increased human to human interaction in assessment is a way to prohibit students relying on AI to complete their learning tasks,” said one respondent from the College of Arts and Sciences, while another said, “Take-home writing is less trustworthy; I may require to see multiple drafts of take-home writing.”

Of professors who were surveyed, the most common ways that evaluation methods were being changed were with an increase in oral examinations, higher percentage of class grades decided by participation, and an increase in in-class writing assignments.

The increase in in-class writing assignments as a solution worries Professor Bauknight. He believes that the writing process takes time and students need that time to be creative and effectively learn from their writing. He mentions an exercise he does with his Creative Writing students in class where he says, “Quick! Be creative!” and has them write in class. Needless to say, this does not work and stresses out students.

Engineering professors again seemed unworried about evaluation, with one faculty member saying, “Most of the deliverables for my class are physical output, not written output, thus there is little fear AI tools can be used to"cheat "."

One of the last questions on the survey directly addressed Provost Urban’s message of Lehigh being a leader in and wanting to plant a flag in AI. When respondents were prompted with the question “Lehigh’s provost has expressed Lehigh’s desire to become a leader in Generative AI and encourage its use in the classroom. Do you think this is a good idea?,” only about 45% of respondents agreed with the provost’s message.

Clearly, two major divides on Generative AI tools still exist at Lehigh: the divide between the provost office and faculty, and the divide between separate colleges at Lehigh. While 
Provost Urban has strived to get these tools implemented early in classrooms and for Lehigh to get a front foot on AI technology such as ChatGPT, the survey results show the level of disdain he has been met with.

“Faculty ultimately have a lot of decision-making power over how they teach and how they assess,” Urban said. He also brought up how many teachers might think they know the full extent of these tools, but in practice he has seen professors be stunned by what these tools can truly do. In one specific instance, Urban had approached a coding professor about the use of AI in code. While the professor knew that AI wrote essays and could answer math equations, “they weren’t aware that it writes code, too,” Urban said.  “And I think it's important to make sure that faculty are broadly aware of the kinds of use cases of these tools so that they can think about how it is best to incorporate them into a classroom and into assignments.” 

One major trend that is seen in the faculty survey that was also talked about in the interview with Provost Urban was uncertainty about these Generative AI tools. For example, in the survey question “Lehigh’s provost has expressed Lehigh’s desire to become a leader in Generative AI and encourage its use in the classroom. Do you think this is a good idea?,” over 31% of respondents said “it depends”, and in a free response section about changing of evaluation methods, 12 of the 34 respondents said that they need more information before making any decisions about Generative AI.

These trends worry Urban, as a situation in which there is faculty and student uncertainty about the allowment of AI tools is a dangerous one. To combat this, Urban has urged teachers not to ban AI tools yet. 

On top of combating confusion, Urban also wants teachers to avoid banning it because he wants students to have access to the best tools possible. “These (Generative AI tools) change the way that we think about education, I think that's kind of been the key element to me,” Urban said. “And I want to make sure that we're doing this in a way that is effective, that is presenting students with the way that these things are going to be used in the real world.”

No matter what your specific opinion on Generative AI tools, one main theme emerged from the survey, faculty interviews, and the interview with the provost: Generative AI technology will have an effect on academia at Lehigh.

“I believe AI will be useful for research and teaching at Lehigh,” said one anonymous survey respondent. “Lehigh should think hard and fast how to use it in the most effective and productive way.”

### Part 2: Student Survey Analysis (Michael)
The rise of Generative AI, particularly ChatGPT, has sparked a debate about its impact on education, especially within the College of Arts and Sciences. As students and faculty grapple with the integration of AI into the learning process, concerns about academic integrity and the need for clear guidelines emerge. 

Generative AI has become an increasingly popular tool among students for various tasks, from studying and writing to job applications. One Lehigh student reports using AI to reduce anxiety and fear of judgment when generating outlines and writing emails. Others have found it helpful in summarizing textbook readings, by making them more concise and understandable.

Researchers for the Brown and White sent out an anonymous, voluntary survey to Lehigh students to gauge student perspectives on ChatGPT and Generative AI. We received 86 responses, with about 80% of these responses from the College of Arts and Sciences. The findings show that the majority of respondents are not engaging with Generative AI at all.

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/Michael%20graph%201.png?raw=true)

Of survey respondents, 77% of students responded between never and sometimes when using ChatGPT or other Generative AI tools, while 90% of students responded to not using Generative AI tools for class. Despite this, roughly 63% of participants view Generative AI as a useful tool, while others express concern about its potential to compromise academic integrity. These concerns are echoed by the Provost, who has also shared apprehensions about not knowing what constitutes cheating when using AI.

During an interview with Dean Dr. Flowers, he acknowledged the benefits of using ChatGPT and stated that, given its widespread popularity, it is essential for students to learn how to use it ethically. In this context, it is better to prepare students for this new reality, Dr. Flowers mentioned the possibility of adding specific classes to the curriculum, focusing on the general and responsible use of AI technology like ChatGPT. He believes that such courses will help students navigate the rapidly evolving technological landscape more effectively and make informed decisions in their academic and professional lives.

In order to understand why so many students look away from using ChatGPT, we should understand that several factors exist, such as a lack of awareness and ethical concerns. Students who are not familiar with AI technologies might not know that such technology exists, so it is important to enabling students to participate in AI-focused events. With the potential of breaking academic integrity, students might feel discouraged to use these tools. It is essential for the university to focus on educating students about responsible AI usage, which can help alleviate some of their concerns, allowing for more widespread use among students.

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/michael%20graph%202.png?raw=true)

Despite the Provost’s messages encouraging the use of Generative AI in the classroom, students report that 70% of professors have not frequently addressed or mentioned ChatGPT or other Generative AI tools in their classes and that 90% of their classes have not allowed its use. This lack of communication between faculty and students has contributed to the confusion and concerns surrounding the potential for cheating with AI.

While concerns about cheating persist, the question of whether Generative AI can be considered cheating is complex. Students are divided on the issue, with some drawing parallels to other resources such as Chegg and Google. Based on survey results, 62% of students are concerned about peers using ChatGPT to cheat. In this context, the majority of students are seeking clearer guidelines on using AI in their coursework.

As one student noted, as of now, the role of AI tools within the university is not entirely clear. An effective approach could be to educate students on how to best utilize these tools while recognizing limitations in and outside of the classroom. Namely, it is important to teach students how to extract the most from these tools while not becoming overly reliant. This will ensure that students are using AI tools purposefully while, at the same time, increasing student productivity and keeping cheating at a minimum. This will open more opportunities for students to develop into well-rounded professionals while maintaining their critical thinking and problem-solving abilities.

In a recent interview with Dr. Papadimitriou, a management professor from the College of Business, she shared her strategy for changing her approach to course assignments, more specifically through her case study analysis assignments. She explained that she revised the coursework by requiring students to answer and ask additional questions as well as engage in group discussions. This more interactive approach allowed for more collaboration between groups and placed a lower emphasis on the reliability of generative AI in the learning process. Additionally, Dr. Papadimitriou has incorporated more oral activities to further enrich and legitimize the educational process. However, she acknowledged that implementing this approach in larger classes might prove challenging due to the increased number of students resulting in difficulties in facilitating effective group discussions.

The takeaway? More guidance from faculty and a clause in every syllabus that clarifies how Generative AI should be used in the classroom. As Dean Flowers noted, faculty should be more clear when setting the boundary of ChatGPT use in class. Many feel that the lack of clear-cut rules has students walking a fine line between using a useful tool and potentially cheating. They also hope that faculty will become more invested in understanding how AI can help students, rather than focusing solely on concerns about cheating. As one student said, “Trying to fight against the use of AI like ChatGPT would be difficult. Any professor who refuses to accept ChatGPT is wasting their energy.”

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/Michael%20graph%204.png?raw=true)

Generative AI has also sparked what an article from Stanford Education calls “an existential motivation crisis” among students, who are grappling with what skills they will need in the future. They are concerned about the potential impact of AI on their careers and how they will work alongside these tools. From survey data, 59% of Lehigh students think Generative AI will have an impact on their future careers, with 30% of students being unsure. In the face of this uncertainty, many believe that success will come down to effectively using AI tools, highlighting the importance of addressing these concerns in the educational context.

The concerns surrounding Generative AI and its potential impact on critical thinking and compelling writing is what one student called the 'Google effect'. In the past, people worried that access to all human knowledge would hinder our ability to learn, or how philosophers opposed writing due to fears of humans losing their memory skills without writing things down.

However, it's essential to recognize that human creativity will always have a place in our society. Even if Generative AI can handle some of the more everyday tasks or produce fluent text, it cannot replace our need to practice creativity and critical thinking. 

It's crucial to acknowledge that AI relies on human involvement as it continues to develop. As we consider AI's role in our future careers, it's vital to understand that we cannot depend entirely on AI for decision-making. While AI can undoubtedly boost the effectiveness of completing both non-professional and professional tasks, it should be utilized as an instrument to support human decision-making.

Nevertheless, as one student noted, it's crucial to be cautious about how big capitalist companies might exploit AI for profit, potentially causing unintended negative consequences for everyone involved.

The debate surrounding Generative AI in the College of Arts and Sciences highlights the need for clear guidelines and faculty support. As students navigate the opportunities and challenges presented by AI, the focus should be on harnessing its potential for learning, while preserving academic integrity and preparing students for future job opportunities. By working together, students and faculty, in and outside of the classroom, can take action to use Generative AI as a powerful tool, rather than just another everyday cheating tool. 

### Part 3 (Isabel): Ethics and does the community want to be a leader?
![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/isabeldrawing1.png?raw=true)

Emails from Lehigh’s Provost Nathan Urban express a desire for Lehigh to become a leader in Artificial Intelligence, but recent media has brought to light many different ethical concerns surrounding Generative AI tools. ChatGPT, a Generative AI tool that generates text in response to prompts from the user, has recently come under fire for many different ethical concerns, including spreading misinformation and encoding gender, racial, ethnic and ability bias.

According to The New York Times, ChatGPT can “hallucinate” and generate “factually incorrect answers.” Lehigh students and faculty are aware of this. One first-year student described a scenario in one of their Psychology classes where the professor used ChatGPT to find references for a topic. The student said that of the 5 sources generated, 3 were fake. 

Professor Lopresti, a CSE Professor at Lehigh, had a similar experience where the AI was unable to perform simple math tasks. “It is a program,” he said, “It doesn’t really understand even though it sounds like it’s confident.” An English 002 student put it succinctly: “It can’t do math.”

Two other students wrote in a survey that they have trouble trusting Generative AI models’ output, especially when using it to search for information. With ChatGPT, there is no way for users to identify an accountable source or find where the information presented came from.

Other than simply getting facts wrong, Generative AI models that generate text like BingAI, ChatGPT, and others can also be used to create and spread misinformation in a persuasive manner that looks like it was written by a human. One student surveyed expressed concern about not being able to identify AI-generated text. 

As these tools become more powerful, it will be hard to discern whether writing is produced by humans or AI. OpenAI, the creators of ChatGPT, released a tool in January designed to detect AI-generated text, but it can only correctly identify AI-generated text 26 percent of the time. 

This inability to identify AI-generated text is particularly concerning in terms of misinformation. NewsGuard, a company that tracks misinformation online, used ChatGPT to write content that furthers misinformation about vaccines: with results The New York Times characterizes as concerning.

“Students need to learn that such services are not trustworthy,” a faculty member responding to our survey said, “at least for now, they cannot really do a literature search, and many other kinds of problems are not solved well by them.”

ChatGPT and other Generative AI models also have problems with bias, says ISE Professor Larry Snyder. Snyder, one of two professors that taught a course on Algorithms and Social Justice last semester, explained that these biases come from the training data gathered from the internet that “skews white, male and young.”

Provost Nathan Urban is also concerned with bias in the output of these models and pointed to efforts by companies to fix them, but, he noted, “they won’t be perfect.”

Snyder said that the newer models of ChatGPT have less overt biases but still contain pernicious bias. He and a colleague, Professor Edwards, conducted an experiment on gender bias with ChatGPT-4 by asking it ten times for a story about a doctor and ten times for a story about a nurse. They found that while ChatGPT mixed up he/she pronouns in the stories generated about the doctor, it generated she/her pronouns in all ten stories about the nurse. There were no mentions of non-binary or other gender identities. 

Snyder said that while newer versions “might be better on the surface, it is not underneath” and that it is impossible to train such large language models on unbiased data. So, these harmful yet subtle biases will never be completely eliminated.

In an open repository documenting errors by ChatGPT, one user found a way to “trick” the newer version of ChatGPT into revealing bias by asking it to write Python code to decide if a person should be tortured based on age, sex, ethnicity, and nationality.

![ScreenShot](https://github.com/bpd223/bpd223.github.io/blob/main/isabel%20picture.png?raw=true)

ChatGPT determined that if you are less than 18, Caucasian and American, or female, you should not be tortured. And if you are anyone else, ChatGPT-generated code believes you could be tortured.

Although Provost Urban expressed concern about ethical issues in Generative AI, at the time of our faculty survey, at least one faculty member did not see that sentiment in his emails. The professor, from the College of Arts and Sciences, wrote: “There has been no public discussion of how these tools amplify bias--and the email from the Provost showed that this was not part of his thinking either. I would like to know how ChatGPT relates to the University's commitment to diversity, equity, and inclusion.”

In response to both misinformation and bias in ChatGPT, Lehigh faculty and Provost Urban agree that teaching students to think critically about AI-generated text is necessary. Some professors compare ChatGPT to any other source that you would use on the internet, encouraging students to be skeptical. Provost Urban wants students to look at generated output and think: “What does the internet know, and what do I know,” as a way to be critical.

There seems to be consensus that students can be taught to identify and critically examine both misinformation and bias in Generative AI models outputs. (But, from our voluntary student survey discussed above, we found that 70 percent of classes are not frequently addressing Generative AI and 90 percent are not frequently allowing its use).

The speed and scope with which Generative AI can create and disseminate misinformation cannot be understated, nor overlooked. Provost Urban hopes that the University can identify and educate students on ethical use cases for these tools.

Generative AI tools also complicate ethical considerations surrounding plagiarism as these tools are trained on data that is collected without the consent or knowledge of the original creators. 
Professor Snyder noted that this very article could be used as training data without his knowledge or consent and without consent from the authors at The Brown and White. 

Snyder also stresses other ethical issues that are often overlooked, including content moderation and labeling, and high energy costs.

Content moderation and data labeling work is done by humans and is often outsourced to low-wage labor overseas which can be traumatizing, according to Snyder. An investigation by the Times found that ChatGPT used Kenyan workers to reduce harmful outputs (by reading and labeling them) for 2 dollars an hour. This hidden and exploited labor is the human cost of these large language models.

Additionally, generating, holding and maintaining the data for training has enormous energy costs. A scholarly article titled “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” shows that “the amount of compute used to train the largest deep learning models (for Natural Language Processing and other applications) has increased 300,000x in 6 years.”

Synder said that the climate change impacts will be felt by people that are not benefitting from this tool. Indeed, the authors of Stochastic Parrots echo his point, writing, “well documented in the literature on environmental racism that the negative effects of climate change are reaching and impacting the world’s most marginalized communities first.” They go on to say, “And, while some language technology is genuinely designed to benefit marginalized communities, most language technology is built to serve the needs of those who already have the most privilege in society.”

While Snyder agreed with Provost Urban in that it is short-sighted to ban the tool, he said “it's important for us to be thinking really carefully about whether, when, how, and why we use it in the classroom.” Snyder believes the most important questions the Lehigh community must grapple with are, “who is benefited and who is harmed,” by these emerging Generative AI technologies. 

And perhaps more importantly, what will we do about the answer? Snyder said, “These are not just technical problems. They are societal problems. Those bad biases, baked into the technology because that's just that problem. That bias exists in society. And so the relationship between society and technology is part of the problem. And that would have to be part of the answer, part of the solution.” How can Lehigh become part of the solution while engaging with Generative AI tools?

## Jour375 Projects
